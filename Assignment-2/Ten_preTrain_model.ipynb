{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514c4950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= VGG16 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 2.75%\n",
      "--- Activation: softmax\n",
      "Accuracy: 4.45%\n",
      "--- Activation: tanh\n",
      "Accuracy: 7.20%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 6.70%\n",
      "\n",
      "================= VGG19 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 1.95%\n",
      "--- Activation: softmax\n",
      "Accuracy: 5.05%\n",
      "--- Activation: tanh\n",
      "Accuracy: 4.80%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 8.10%\n",
      "\n",
      "================= ResNet50 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 3.90%\n",
      "--- Activation: softmax\n",
      "Accuracy: 4.70%\n",
      "--- Activation: tanh\n",
      "Accuracy: 5.90%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 6.25%\n",
      "\n",
      "================= InceptionV3 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 5.15%\n",
      "--- Activation: softmax\n",
      "Accuracy: 5.80%\n",
      "--- Activation: tanh\n",
      "Accuracy: 6.75%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 5.80%\n",
      "\n",
      "================= Xception =================\n",
      "--- Activation: relu\n",
      "Accuracy: 5.55%\n",
      "--- Activation: softmax\n",
      "Accuracy: 6.70%\n",
      "--- Activation: tanh\n",
      "Accuracy: 4.80%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 5.95%\n",
      "\n",
      "================= MobileNet =================\n",
      "--- Activation: relu\n",
      "Accuracy: 3.00%\n",
      "--- Activation: softmax\n",
      "Accuracy: 3.45%\n",
      "--- Activation: tanh\n",
      "Accuracy: 7.20%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 5.35%\n",
      "\n",
      "================= DenseNet121 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 6.55%\n",
      "--- Activation: softmax\n",
      "Accuracy: 4.95%\n",
      "--- Activation: tanh\n",
      "Accuracy: 6.55%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 2.80%\n",
      "\n",
      "================= EfficientNetB1 =================\n",
      "--- Activation: relu\n",
      "Accuracy: 3.70%\n",
      "--- Activation: softmax\n",
      "Accuracy: 3.85%\n",
      "--- Activation: tanh\n",
      "Accuracy: 3.90%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 4.35%\n",
      "\n",
      "================= NASNetMobile =================\n",
      "--- Activation: relu\n",
      "Accuracy: 4.50%\n",
      "--- Activation: softmax\n",
      "Accuracy: 7.35%\n",
      "--- Activation: tanh\n",
      "Accuracy: 6.85%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 4.20%\n",
      "\n",
      "================= NASNetLarge =================\n",
      "--- Activation: relu\n",
      "Accuracy: 4.50%\n",
      "--- Activation: softmax\n",
      "Accuracy: 3.60%\n",
      "--- Activation: tanh\n",
      "Accuracy: 4.85%\n",
      "--- Activation: sigmoid\n",
      "Accuracy: 3.50%\n",
      "\n",
      "======================= Accuracy Summary =======================\n",
      "VGG16           | relu: 2.75% | softmax: 4.45% | tanh: 7.20% | sigmoid: 6.70% | \n",
      "VGG19           | relu: 1.95% | softmax: 5.05% | tanh: 4.80% | sigmoid: 8.10% | \n",
      "ResNet50        | relu: 3.90% | softmax: 4.70% | tanh: 5.90% | sigmoid: 6.25% | \n",
      "InceptionV3     | relu: 5.15% | softmax: 5.80% | tanh: 6.75% | sigmoid: 5.80% | \n",
      "Xception        | relu: 5.55% | softmax: 6.70% | tanh: 4.80% | sigmoid: 5.95% | \n",
      "MobileNet       | relu: 3.00% | softmax: 3.45% | tanh: 7.20% | sigmoid: 5.35% | \n",
      "DenseNet121     | relu: 6.55% | softmax: 4.95% | tanh: 6.55% | sigmoid: 2.80% | \n",
      "EfficientNetB1  | relu: 3.70% | softmax: 3.85% | tanh: 3.90% | sigmoid: 4.35% | \n",
      "NASNetMobile    | relu: 4.50% | softmax: 7.35% | tanh: 6.85% | sigmoid: 4.20% | \n",
      "NASNetLarge     | relu: 4.50% | softmax: 3.60% | tanh: 4.85% | sigmoid: 3.50% | \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, ResNet50, InceptionV3, Xception,\n",
    "    MobileNet, DenseNet121, EfficientNetB1,\n",
    "    NASNetMobile, NASNetLarge\n",
    ")\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_pre\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_pre\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_pre\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_pre\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_pre\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_pre\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input as nasnet_pre\n",
    "\n",
    "#======================= Load CIFAR-100 and prepare 20-class subset =========================#\n",
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "trainY = trainY.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "selected_classes = random.sample(range(100), 20)\n",
    "class_map = {original: new for new, original in enumerate(selected_classes)}\n",
    "\n",
    "test_mask = np.isin(testY, selected_classes)\n",
    "testX, testY = testX[test_mask], testY[test_mask]\n",
    "testY = np.vectorize(class_map.get)(testY)\n",
    "\n",
    "testX_resized = tf.image.resize(testX, (224, 224)).numpy()\n",
    "\n",
    "#======================= Pretrained model config ===========================================#\n",
    "models_config = {\n",
    "    \"VGG16\": (VGG16, vgg16_pre),\n",
    "    \"VGG19\": (VGG19, vgg19_pre),\n",
    "    \"ResNet50\": (ResNet50, resnet_pre),\n",
    "    \"InceptionV3\": (InceptionV3, inception_pre),\n",
    "    \"Xception\": (Xception, xception_pre),\n",
    "    \"MobileNet\": (MobileNet, mobilenet_pre),\n",
    "    \"DenseNet121\": (DenseNet121, densenet_pre),\n",
    "    \"EfficientNetB1\": (EfficientNetB1, efficientnet_pre),\n",
    "    \"NASNetMobile\": (NASNetMobile, nasnet_pre),\n",
    "    \"NASNetLarge\": (NASNetLarge, nasnet_pre)\n",
    "}\n",
    "\n",
    "#======================= Activations to evaluate ===========================================#\n",
    "activations = [\"relu\", \"softmax\", \"tanh\", \"sigmoid\"]\n",
    "results = {}  #{model: {activation: accuracy}}\n",
    "\n",
    "#======================= Evaluation Loop ===================================================#\n",
    "for model_name, (ModelClass, preprocess_fn) in models_config.items():\n",
    "    print(f\"\\n================= {model_name} =================\")\n",
    "    results[model_name] = {}\n",
    "\n",
    "    testX_preprocessed = preprocess_fn(testX_resized.copy())\n",
    "    base_model = ModelClass(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    for activation in activations:\n",
    "        print(f\"--- Activation: {activation}\")\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        output = Dense(20, activation=activation)(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=output, name=f\"{model_name}_{activation}\")\n",
    "        y_pred_probs = model.predict(testX_preprocessed, verbose=0)\n",
    "\n",
    "        # Use softmax to get predictions if activation is not softmax\n",
    "        if activation == \"softmax\":\n",
    "            predY = np.argmax(y_pred_probs, axis=1)\n",
    "        else:\n",
    "            predY = np.argmax(tf.nn.softmax(y_pred_probs, axis=1), axis=1)\n",
    "\n",
    "        acc = accuracy_score(testY, predY) * 100\n",
    "        results[model_name][activation] = acc\n",
    "        print(f\"Accuracy: {acc:.2f}%\")\n",
    "\n",
    "#======================= Summary Report ====================================================#\n",
    "print(\"\\n======================= Accuracy Summary =======================\")\n",
    "for model, acc_dict in results.items():\n",
    "    print(f\"{model:15}\", end=\" | \")\n",
    "    for activation in activations:\n",
    "        print(f\"{activation}: {acc_dict[activation]:.2f}%\", end=\" | \")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
